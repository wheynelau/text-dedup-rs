{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_dedup.minhash_spark import generate_hash_values, generate_edges, ngram_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "from typing import List\n",
    "def ngrams(sequence: List[str], n: int, min_length: int = 5):\n",
    "    \"\"\"\n",
    "    Return the ngrams generated from a sequence of items, as an iterator.\n",
    "\n",
    "    This is a modified version of nltk.util.ngrams.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : List[Text]\n",
    "        The sequence of items.\n",
    "    n : int\n",
    "        The length of each ngram.\n",
    "    min_length : int, optional\n",
    "        The minimum length of each ngram, by default 5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iterator\n",
    "        The ngrams.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> list(ngrams([\"a\", \"b\", \"c\", \"d\"], 2, min_length=1))\n",
    "    [('a', 'b'), ('b', 'c'), ('c', 'd')]\n",
    "    >>> list(ngrams([\"a\", \"b\", \"c\", \"d\"], 2, min_length=5))\n",
    "    []\n",
    "    >>> list(ngrams([\"a\", \"b\"], 3, min_length=1))\n",
    "    [('a', 'b')]\n",
    "    \"\"\"\n",
    "    if len(sequence) < min_length:\n",
    "        return []\n",
    "    if len(sequence) < n:\n",
    "        return [tuple(sequence)]\n",
    "    iterables = tee(iter(sequence), n)\n",
    "    for i, sub_iterable in enumerate(iterables):\n",
    "        for _ in range(i):\n",
    "            next(sub_iterable, None)\n",
    "    return zip(*iterables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import struct\n",
    "\n",
    "def sha1_hash(data: bytes, d: int = 32) -> int:\n",
    "    \"\"\"\n",
    "    Generate a d-bit hash value from the given data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : bytes\n",
    "        The data to be hashed.\n",
    "    d : int\n",
    "        The number of bits of the hash value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The hash value.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> sha1_hash(b\"hello world\", 32)\n",
    "    896314922\n",
    "    >>> sha1_hash(b\"hello world\", 64)\n",
    "    13028719972609469994\n",
    "    >>> sha1_hash(b\"hello world\", 128)\n",
    "    310522945683037930239412421226792791594\n",
    "    \"\"\"\n",
    "    if d == 32:\n",
    "        return struct.unpack(\"<I\", hashlib.sha1(data, usedforsecurity=False).digest()[:4])[0]\n",
    "    if d == 64:\n",
    "        return struct.unpack(\"<Q\", hashlib.sha1(data, usedforsecurity=False).digest()[:8])[0]\n",
    "    # struct is faster but does not support arbitrary bit lengths\n",
    "    return int.from_bytes(hashlib.sha1(data, usedforsecurity=False).digest()[: d // 8], byteorder=\"little\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "SEED = 42\n",
    "RNG = np.random.RandomState(SEED)\n",
    "NON_ALPHA = re.compile(r\"\\W\", re.UNICODE)\n",
    "SIGNATURE_COLUMN = \"__signatures__\"\n",
    "content = \"But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system, and expound the actual teachings of the great explorer of the truth, the master-builder of human happiness. No one rejects, dislikes, or avoids pleasure itself, because it is pleasure, but because those who do not know how to pursue pleasure rationally encounter consequences that are extremely painful. Nor again is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain, but because occasionally circumstances occur in which toil and pain can procure him some great pleasure. To take a trivial example, which of us ever undertakes laborious physical exercise, except to obtain some advantage from it? But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences, or one who avoids a pain that produces no resultant pleasure?\"\n",
    "\n",
    "tokens: set[bytes] = {\n",
    "        bytes(\" \".join(t).lower(), \"utf-8\") for t in ngrams(NON_ALPHA.split(content.lower()), 3, 5)\n",
    "    }\n",
    "tokens1: set[bytes] = {\n",
    "        bytes(\"\".join(t).lower(), \"utf-8\") for t in ngrams(NON_ALPHA.split(content.lower()), 3, 5)\n",
    "    }\n",
    "\n",
    "hashvalues: np.ndarray = np.array([sha1_hash(token) for token in tokens], dtype=np.uint64).reshape(len(tokens), 1)\n",
    "\n",
    "dtype, max_hash, modulo_prime =  (np.uint64, np.uint32((1 << 32) - 1), np.uint64((1 << 61) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERMUTATIONS: tuple[np.ndarray, np.ndarray] = (\n",
    "        RNG.randint(\n",
    "            1, modulo_prime, size=(200,), dtype=dtype\n",
    "        ),  # a is a multiplier so should not be 0\n",
    "        RNG.randint(0, modulo_prime, size=(200,), dtype=dtype),  # b\n",
    "    )\n",
    "a,b = PERMUTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hashvalues = (hashvalues * a + b) % modulo_prime & max_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM PYSPARK\n",
    "def pyspark():\n",
    "    idx = 0\n",
    "    num_perm = 200\n",
    "    hashranges = [(i * 6, (i + 1) * 6) for i in range(33)]\n",
    "    hashes = np.array(list(ngram_hashes(content, 2, 5)), dtype=dtype)\n",
    "    p_hashes = ((np.outer(hashes, a) + b) % modulo_prime) & max_hash\n",
    "    min_hashes = np.vstack([p_hashes, np.full(num_perm, max_hash, dtype=dtype)]).min(\n",
    "            axis=0\n",
    "    )\n",
    "    return [\n",
    "        (band_idx, min_hashes[start:end].data.tobytes(), idx)\n",
    "        for band_idx, (start, end) in enumerate(hashranges)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks: np.ndarray = np.full(shape=200, dtype=dtype, fill_value=max_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashvalues = (hashvalues * a + b) % modulo_prime & max_hash\n",
    "    # this part is where the name \"min\" of minhash comes from\n",
    "    # this stacks all the hashes and then takes the minimum from each column\n",
    "num_perm = 200\n",
    "hashranges = [(i * 6, (i + 1) * 6) for i in range(33)]\n",
    "masks: np.ndarray = np.full(shape=num_perm, dtype=dtype, fill_value=max_hash)\n",
    "hashvalues = np.vstack([hashvalues, masks]).min(axis=0)\n",
    "# Originally, byteswap was done for speed. Testing show it has a negligible impact\n",
    "# keeping  for backward compatibility, even though theoretically and empirically\n",
    "# it doesnt matter if it is there or not. github.com/ekzhu/datasketch/issues/114\n",
    "Hs: list[bytes] = [bytes(hashvalues[start:end].byteswap().data) for start, end in hashranges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6\n",
      "b'\\xd8\\xc6\\x8e\\x00\\x00\\x00\\x00\\x00s\\x8a\\xe1\\x00\\x00\\x00\\x00\\x00\\x8dM{\\x00\\x00\\x00\\x00\\x00\\x05\\x8f\\x00\\x00\\x00\\x00\\x00\\x00\\xccV*\\x02\\x00\\x00\\x00\\x00\\xa9\\xe7\\x86\\x01\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "for start,end in hashranges: # hashranges is a list of indices\n",
    "    print(start,end)\n",
    "    mem = (hashvalues[start:end].data)\n",
    "    utf8 = bytes(mem)\n",
    "    print(utf8) # this usually breaks but its intended as the program doesn need to decode it\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9357016, 14781043,  8080781,    36613, 36329164, 25618345],\n",
       "      dtype=uint64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashvalues[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rust_out =  r\"�L�\\u{f}\\0\\0\\0\\0Q�@\\r\\0\\0\\0\\0���\\u{3}\\0\\0\\0\\0%��\\u{c}\\0\\0\\0\\0Z��\\u{1}\\0\\0\\0\\0F�\\u{7f}\\u{3}\\0\\0\\0\\0\"\n",
    "\n",
    "rust_out = rust_out.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 142, 198, 216, 0, 0, 0, 0, 0, 225, 138, 115, 0, 0, 0, 0, 0, 123, 77, 141, 0, 0, 0, 0, 0, 0, 143, 5, 0, 0, 0, 0, 2, 42, 86, 204, 0, 0, 0, 0, 1, 134, 231, 169]\n"
     ]
    }
   ],
   "source": [
    "print(list(Hs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 15, 146, 76, 214, 0, 0, 0, 0, 13, 64, 158, 81, 0, 0, 0, 0, 3, 247, 225, 216, 0, 0, 0, 0, 12, 219, 184, 37, 0, 0, 0, 0, 1, 197, 133, 90, 0, 0, 0, 0, 3, 127, 203, 70]\n"
     ]
    }
   ],
   "source": [
    "print(rust_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xd6L\\x92\\x0f\\x00\\x00\\x00\\x00Q\\x9e@\\r\\x00\\x00\\x00\\x00\\xd8\\xe1\\xf7\\x03\\x00\\x00\\x00\\x00%\\xb8\\xdb\\x0c\\x00\\x00\\x00\\x00Z\\x85\\xc5\\x01\\x00\\x00\\x00\\x00F\\xcb\\x7f\\x03\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([214, 76, 146, 15, 0, 0, 0, 0, 81, 158, 64, 13, 0, 0, 0, 0, 216, 225, 247, 3, 0, 0, 0, 0, 37, 184, 219, 12, 0, 0, 0, 0, 90, 133, 197, 1, 0, 0, 0, 0, 70, 203, 127, 3, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rust_int = [\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    15,\n",
    "    146,\n",
    "    76,\n",
    "    214,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    13,\n",
    "    64,\n",
    "    158,\n",
    "    81,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    3,\n",
    "    247,\n",
    "    225,\n",
    "    216,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    12,\n",
    "    219,\n",
    "    184,\n",
    "    37,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    197,\n",
    "    133,\n",
    "    90,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    3,\n",
    "    127,\n",
    "    203,\n",
    "    70,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_dedup.minhash import embed_func\n",
    "from text_dedup.dedup_rs import EmbedFunc\n",
    "import datasets as ds\n",
    "\n",
    "Emb = EmbedFunc(threshold =0.5, num_perm=200, false_positive=0.5, false_negative=0.5,\n",
    "                main_col = \"__SIGNATURE__\", idx_col = \"__idx__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'builtins.EmbedFunc'>: attribute lookup EmbedFunc on builtins failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_func.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEmb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'builtins.EmbedFunc'>: attribute lookup EmbedFunc on builtins failed"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"embed_func.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Emb, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
